{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLProj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VJV3bj-sQp_DTWyl93zgq0ZUZN8rK4W_",
      "authorship_tag": "ABX9TyOtueraNzDPnHichqAHmBS/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinle350/ML_Reddit_Stock_Sentiment_Predictor/blob/main/DLProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FabCN-YtIsd"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib import rcParams\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "import string\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "%matplotlib inline\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5QjufrUER_Q",
        "outputId": "f7cd6c91-3fc0-4638-eb00-a29424fc24e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc7juxEAu-yo",
        "outputId": "a98155aa-3109-4428-9a46-58ca56586dfa"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "import os \n",
        "folder = os.path.join('/content/drive/MyDrive/UIUC/NOBE/training.1600000.processed.noemoticon.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: google-drive-ocamlfuse: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5V1A4cfRxc-"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/UIUC/NOBE/training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\", engine=\"python\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9vZ1mmyTJjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d07b86b5-66e1-4f69-a64d-8ca4ca8df206"
      },
      "source": [
        "df.columns = [\"label\", \"time\", \"date\", \"query\", \"username\", \"text\"]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>time</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                               text\n",
              "0      0  ...  is upset that he can't update his Facebook by ...\n",
              "1      0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "2      0  ...    my whole body feels itchy and like its on fire \n",
              "3      0  ...  @nationwideclass no, it's not behaving at all....\n",
              "4      0  ...                      @Kwesidei not the whole crew \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "j96jZa85P6Ww",
        "outputId": "33ecd32c-4b2e-4cbb-8161-4dcbc3c97bcd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>time</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                               text\n",
              "0      0  ...  is upset that he can't update his Facebook by ...\n",
              "1      0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "2      0  ...    my whole body feels itchy and like its on fire \n",
              "3      0  ...  @nationwideclass no, it's not behaving at all....\n",
              "4      0  ...                      @Kwesidei not the whole crew \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikk8u3M_QFRi",
        "outputId": "5d7c57a2-7db9-42b0-9342-6f251eef8d16"
      },
      "source": [
        "df['label'][df['label'] == 0] = -1\n",
        "df['label'][df['label'] == 2] = 0\n",
        "df['label'][df['label'] == 4] = 1\n",
        "df['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         -1\n",
              "1         -1\n",
              "2         -1\n",
              "3         -1\n",
              "4         -1\n",
              "          ..\n",
              "1599994    1\n",
              "1599995    1\n",
              "1599996    1\n",
              "1599997    1\n",
              "1599998    1\n",
              "Name: label, Length: 1599999, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcP4s43jQVuH",
        "outputId": "8110cf15-6552-4c6b-b9cf-857f5d5c9792"
      },
      "source": [
        "df['text'] = df['text'].str.lower()\n",
        "df['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          is upset that he can't update his facebook by ...\n",
              "1          @kenichan i dived many times for the ball. man...\n",
              "2            my whole body feels itchy and like its on fire \n",
              "3          @nationwideclass no, it's not behaving at all....\n",
              "4                              @kwesidei not the whole crew \n",
              "                                 ...                        \n",
              "1599994    just woke up. having no school is the best fee...\n",
              "1599995    thewdb.com - very cool to hear old walt interv...\n",
              "1599996    are you ready for your mojo makeover? ask me f...\n",
              "1599997    happy 38th birthday to my boo of alll time!!! ...\n",
              "1599998    happy #charitytuesday @thenspcc @sparkscharity...\n",
              "Name: text, Length: 1599999, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqOBu_5AQiKA",
        "outputId": "04e18045-e67d-4b83-85c7-d21fac1b020c"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Utq_zfQmaN",
        "outputId": "c4593df9-81b2-4923-97b0-505a3c00f469"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtfaoAgBQwF7"
      },
      "source": [
        "def clean_stop_words(text):\n",
        "  word_list = str(text).split()\n",
        "  cleaned_word_list = []\n",
        "  for word in word_list:\n",
        "    if word not in stop_words:\n",
        "      cleaned_word_list.append(word)\n",
        "  return \" \".join(cleaned_word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeFSHrXUS2Kk"
      },
      "source": [
        "def clean_at(text):\n",
        "  split_text = text.split()\n",
        "  non_at_words = []\n",
        "  for word in split_text:\n",
        "    if not re.search(\".*@.*\", word):\n",
        "      non_at_words.append(word)\n",
        "  return \" \".join(non_at_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_GlTXbERB7"
      },
      "source": [
        "english_punctuations = string.punctuation\n",
        "punctuations_list = english_punctuations\n",
        "def clean_punctuation(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noP1BBpjFzud"
      },
      "source": [
        "def clean_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB_VluuKmfXH"
      },
      "source": [
        "def clean_urls(data):\n",
        "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFuN07W8FjJx"
      },
      "source": [
        "def clean_nums(data):\n",
        "    return re.sub('[0-9]+', '', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWsRp5YQGKFp",
        "outputId": "c63ac663-cd7b-44ce-be5e-d14647615944"
      },
      "source": [
        "print(\"Cleaning stop words...\")\n",
        "df['text'] = df['text'].apply(lambda tweet: clean_stop_words(tweet))\n",
        "print(\"Cleaning words with @...\")\n",
        "df['text'] = df['text'].apply(lambda tweet: clean_at(tweet))\n",
        "print(\"Cleaning punctuation...\")\n",
        "df['text'] = df['text'].apply(lambda tweet: clean_punctuation(tweet))\n",
        "print(\"Cleaning urls...\")\n",
        "df['text'] = df['text'].apply(lambda tweet: clean_urls(tweet))\n",
        "print(\"Cleaning repeating characters...\")\n",
        "df['text'] = df['text'].apply(lambda tweet: clean_repeating_char(tweet))\n",
        "print(\"Cleaning numeric characters...\")\n",
        "df['text'] = df['text'].apply(lambda tweet: clean_nums(tweet))\n",
        "print(\"Done cleaning\")\n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning stop words...\n",
            "Cleaning words with @...\n",
            "Cleaning punctuation...\n",
            "Cleaning urls...\n",
            "Cleaning repeating characters...\n",
            "Cleaning numeric characters...\n",
            "Done cleaning\n",
            "   label  ...                                               text\n",
            "0     -1  ...  upset cant update facebok texting it might cry...\n",
            "1     -1  ...  dived many times bal managed save  rest go bounds\n",
            "2     -1  ...                    whole body fels itchy like fire\n",
            "3     -1  ...           no behaving al im mad here cant se there\n",
            "4     -1  ...                                         whole crew\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzaVG6FmI9z7"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "df['text'] = df['text'].apply(tokenizer.tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLQCJqqvJO3E",
        "outputId": "f30d7918-3ac0-4c23-c66e-6656049fce19"
      },
      "source": [
        "df.head()\n",
        "df['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          [upset, cant, update, facebok, texting, it, mi...\n",
              "1          [dived, many, times, bal, managed, save, rest,...\n",
              "2                     [whole, body, fels, itchy, like, fire]\n",
              "3          [no, behaving, al, im, mad, here, cant, se, th...\n",
              "4                                              [whole, crew]\n",
              "                                 ...                        \n",
              "1599994                [woke, up, schol, best, feling, ever]\n",
              "1599995    [thewdbcom, col, hear, old, walt, interviews, ...\n",
              "1599996                [ready, mojo, makeover, ask, details]\n",
              "1599997    [hapy, th, birthday, bo, al, time, tupac, amar...\n",
              "1599998                               [hapy, charitytuesday]\n",
              "Name: text, Length: 1599999, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-mgt_p3MLll"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "def stemming_test(data):\n",
        "  text = [ps.stem(word) for word in data]\n",
        "  return data\n",
        "  df['text'] = df['text'].apply(lambda x: stemming_test(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwjwx6QGwwJ6",
        "outputId": "73429397-d931-4fc4-934b-75b39cd2ae2a"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "def lemmatizing_test(data):\n",
        "  text = [lemmatizer.lemmatize(word) for word in data]\n",
        "  return data\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: lemmatizing_test(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQb82vfjR6Tx"
      },
      "source": [
        "max_len = 500\n",
        "tok = Tokenizer(num_words=2000)\n",
        "tok.fit_on_texts(df['text'])\n",
        "sequences = tok.texts_to_sequences(df['text'])\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb7oZv4UOXzu"
      },
      "source": [
        "df['label'][df['label'] == 0] = 0.5\n",
        "df['label'][df['label'] == -1] = 0\n",
        "df['label'][df['label'] == 1] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbl2Se0sxjEE"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(sequences_matrix, df['label'] , test_size = 0.7, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXBHSzZQY7Ak"
      },
      "source": [
        "def nm_model():\n",
        "  model = Input(shape = [500]);\n",
        "  layer1 = model\n",
        "  model = Embedding(input_dim = 2000, output_dim = 500, input_length = 500)(model);\n",
        "  lstm = LSTM(64);\n",
        "  model = lstm(model)\n",
        "  model = Dense(256)(model)\n",
        "  model = Activation('relu')(model)\n",
        "  model = Dropout(.5)(model)\n",
        "  model = Dense(1)(model)\n",
        "  b = Activation(\"sigmoid\")\n",
        "  model = b(model)\n",
        "  return Model(inputs = layer1, outputs = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TVzjxT-YkQ0",
        "outputId": "df60827b-b0da-4bac-9796-d751f68488aa"
      },
      "source": [
        "model = nm_model()\n",
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "history=model.fit(X_train[:40000], Y_train[:40000], batch_size=100, epochs=6, validation_split=0.1)\n",
        "print('Training finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "360/360 [==============================] - 62s 80ms/step - loss: 0.5887 - accuracy: 0.6733 - val_loss: 0.5033 - val_accuracy: 0.7558\n",
            "Epoch 2/6\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.4908 - val_accuracy: 0.7613\n",
            "Epoch 3/6\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.4615 - accuracy: 0.7789 - val_loss: 0.4962 - val_accuracy: 0.7573\n",
            "Epoch 4/6\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.4386 - accuracy: 0.7933 - val_loss: 0.4969 - val_accuracy: 0.7590\n",
            "Epoch 5/6\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.4261 - accuracy: 0.7994 - val_loss: 0.5121 - val_accuracy: 0.7492\n",
            "Epoch 6/6\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.4014 - accuracy: 0.8123 - val_loss: 0.5154 - val_accuracy: 0.7533\n",
            "Training finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjqUVRoSYPhO",
        "outputId": "39c25c61-0069-40e7-aace-9b215577013e"
      },
      "source": [
        "accr1 = model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35000/35000 [==============================] - 561s 16ms/step - loss: 0.5382 - accuracy: 0.7419\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}